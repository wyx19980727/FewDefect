{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### source code from TFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if cfg.MODEL.BACKBONE.FREEZE:\n",
    "#     for p in self.backbone.parameters():\n",
    "#         p.requires_grad = False\n",
    "#     print(\"froze backbone parameters\")\n",
    "\n",
    "# if cfg.MODEL.PROPOSAL_GENERATOR.FREEZE:\n",
    "#     for p in self.proposal_generator.parameters():\n",
    "#         p.requires_grad = False\n",
    "#     print(\"froze proposal generator parameters\")\n",
    "\n",
    "# if cfg.MODEL.ROI_HEADS.FREEZE_FEAT:\n",
    "#     for p in self.roi_heads.box_head.parameters():\n",
    "#         p.requires_grad = False\n",
    "#     print(\"froze roi_box_head parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check cosine similarity bbox head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.models.utils import build_linear_layer\n",
    "# torch.Size([1024, 256, 7, 7])\n",
    "from torch import nn\n",
    "\n",
    "a= nn.Linear((256,7,7), 7, bias=False)\n",
    "\n",
    "fc_cls = build_linear_layer(\n",
    "    cfg=None,\n",
    "    in_features=256,\n",
    "    out_features=7)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check gradient visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.models import build_detector\n",
    "from mmcv import Config\n",
    "config_path = \"/home/dlsuncheng/FSOD/FsMMdet/Model/cos-ft/frcn_unfreeze_cos.py\"\n",
    "\n",
    "cfg = Config.fromfile(config_path)\n",
    "model = build_detector(\n",
    "    cfg.model,\n",
    "    train_cfg=cfg.get('train_cfg'),\n",
    "    test_cfg=cfg.get('test_cfg'))\n",
    "model.init_weights()\n",
    "for tag, value in model.backbone.named_parameters():  \n",
    "    print(tag)\n",
    "    print(value.grad)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize NEU_DET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python /home/dlsuncheng/FSOD/FsMMdet/MMdet/tools/misc/browse_dataset.py /home/dlsuncheng/FSOD/FsMMdet/Model/cos-ft/frcn_pretrain.py \\\n",
    "#     --output-dir /home/dlsuncheng/Dataset/NEU-DET/VOC2012/Visualize/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coco post analysis\n",
    "\n",
    "#### 1. 总体精度        \n",
    "#### 2. 是否存在错误分类  \n",
    "#### 3. 是否存在漏检\n",
    "#### 4. 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pth_path = \"/home/dlsuncheng/Work_dir/Steel_Defect/20211021/FRCN_all/epoch_21.pth\"\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "def Read_Json(path):\n",
    "    with open(path,\"r\") as load_f:\n",
    "        json_file = json.load(load_f)\n",
    "    return json_file\n",
    "\n",
    "result_path = \"./Result/FRCN_all_test.bbox.json\"\n",
    "test_anno_path = \"/home/dlsuncheng/FSOD/FsMMdet/Datasets/NEU_DET/COCO_Annotation/test.json\"\n",
    "result_json = Read_Json(result_path)\n",
    "test_json = Read_Json(test_anno_path)\n",
    "\n",
    "img_info = pd.DataFrame(columns=[\"image_id\",\"gt_category\",\"pred_category\"])\n",
    "gt_image_id_list = [img_info[\"image_id\"] for img_info in test_json[\"annotations\"]]\n",
    "gt_image_id = list(set(gt_image_id_list))\n",
    "gt_image_id.sort()\n",
    "img_info[\"image_id\"] = gt_image_id\n",
    "\n",
    "## 误分类分析\n",
    "### 同一张图片内的类别应该相同\n",
    "### image_id:[category_ids]\n",
    "pred_category = []\n",
    "gt_category = []\n",
    "for img_id in gt_image_id:\n",
    "    pred_cat_id_list = np.array([img[\"category_id\"] for img in result_json if img[\"image_id\"]==img_id])\n",
    "    gt_cat_id_list = np.array([anno[\"category_id\"] for anno in test_json[\"annotations\"] if anno[\"image_id\"]==img_id])\n",
    "    gt_cat_id = gt_cat_id_list[0]*np.ones(pred_cat_id_list.shape)\n",
    "    pred_category.extend(pred_cat_id_list)\n",
    "    gt_category.extend(gt_cat_id)\n",
    "\n",
    "con=confusion_matrix(gt_category,pred_category)\n",
    "# sn.set()\n",
    "\n",
    "# plt.rcParams['font.sans-serif']=['SimHei']\n",
    "# fig = plt.figure(figsize=(10,10))\n",
    "# sn.heatmap(con,annot = True,linewidths=1)\n",
    "# plt.savefig(\"./cls_heat.png\")\n",
    "# plt.show()\n",
    "### 是否存在漏检\n",
    "# pred_image_id_list = [img_info[\"image_id\"] for img_info in result_json]\n",
    "# pred_bbox_num = dict(Counter(pred_image_id_list))\n",
    "# gt_image_id_list = [img_info[\"image_id\"] for img_info in test_json[\"annotations\"]]\n",
    "# gt_bbox_num = dict(Counter(gt_image_id_list))\n",
    "\n",
    "# pred_num = list(pred_bbox_num.values())\n",
    "# gt_num = list(gt_bbox_num.values())\n",
    "# for index in range(len(pred_num)):\n",
    "#     if pred_num[index]-gt_num[index]<0:\n",
    "#         print(1)\n",
    "\n",
    "## 没有漏检，但是部分图片多出来了很多bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 权重——去除最后一个分类层，和其他多余信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roi_head.bbox_head.fc_cls.weight\n",
      "roi_head.bbox_head.fc_cls.bias\n",
      "roi_head.bbox_head.fc_reg.weight\n",
      "roi_head.bbox_head.fc_reg.bias\n"
     ]
    }
   ],
   "source": [
    "# parser.add_argument('--param-name', type=str, nargs='+',\n",
    "#         default=['roi_heads.box_predictor.cls_score',\n",
    "#                     'roi_heads.box_predictor.bbox_pred'],\n",
    "#         help='Target parameter names')\n",
    "\n",
    "# if args.method == 'remove':\n",
    "#     for param_name in args.param_name:\n",
    "#         del ckpt['model'][param_name + '.weight']\n",
    "#         if param_name+'.bias' in ckpt['model']:\n",
    "#             del ckpt['model'][param_name+'.bias']\n",
    "#     save_ckpt(ckpt, save_path)\n",
    "#     return\n",
    "\n",
    "import torch\n",
    "pth_path = \"/home/dlsuncheng/Work_dir/Steel_Defect/20211021/FRCN_cos-ft/epoch_24.pth\"\n",
    "def reset_ckpt(ckpt):\n",
    "    if 'scheduler' in ckpt:\n",
    "        del ckpt['scheduler']\n",
    "    if 'optimizer' in ckpt:\n",
    "        del ckpt['optimizer']\n",
    "    if 'iteration' in ckpt:\n",
    "        ckpt['iteration'] = 0\n",
    "\n",
    "def save_ckpt(ckpt, save_name):\n",
    "    torch.save(ckpt, save_name)\n",
    "    print('save changed ckpt to {}'.format(save_name))\n",
    "\n",
    "ckpt = torch.load(pth_path)\n",
    "\n",
    "param_name = 'roi_head.bbox_head'\n",
    "\n",
    "for parameter in list(ckpt[\"state_dict\"].keys()):\n",
    "    if \"fc_cls\" in parameter or \"fc_reg\" in parameter:\n",
    "        # del ckpt['state_dict'][parameter]\n",
    "        print(parameter)\n",
    "# reset_ckpt(ckpt)\n",
    "\n",
    "del ckpt[\"meta\"],ckpt[\"optimizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['roi_heads.box_head.fc1.weight', 'roi_heads.box_head.fc1.bias', 'roi_heads.box_head.fc2.weight', 'roi_heads.box_head.fc2.bias', 'roi_heads.box_predictor.cls_score.weight', 'roi_heads.box_predictor.bbox_pred.weight', 'roi_heads.box_predictor.bbox_pred.bias']\n",
      "['roi_heads.box_head.fc1.weight', 'roi_heads.box_head.fc1.bias', 'roi_heads.box_head.fc2.weight', 'roi_heads.box_head.fc2.bias', 'roi_heads.box_predictor.cls_score.weight', 'roi_heads.box_predictor.cls_score.bias', 'roi_heads.box_predictor.bbox_pred.weight', 'roi_heads.box_predictor.bbox_pred.bias']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tfa_cos_path = \"/home/dlsuncheng/FSOD/FsMMdet/Weights/tfa_cos.pth\"\n",
    "tfa_fc_path = \"/home/dlsuncheng/FSOD/FsMMdet/Weights/tfa_fc.pth\"\n",
    "\n",
    "tfa_cos_pth = torch.load(tfa_cos_path)\n",
    "tfa_fc_pth = torch.load(tfa_fc_path)\n",
    "print([param_name for param_name in tfa_cos_pth[\"model\"].keys() if \"roi_heads\" in param_name])\n",
    "print([param_name for param_name in tfa_fc_pth[\"model\"].keys() if \"roi_heads\" in param_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['roi_heads.box_head.fc1.weight', 'roi_heads.box_head.fc1.bias', 'roi_heads.box_head.fc2.weight', 'roi_heads.box_head.fc2.bias', 'roi_heads.box_predictor.cls_score.weight', 'roi_heads.box_predictor.bbox_pred.weight', 'roi_heads.box_predictor.bbox_pred.bias']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65e57e77d9cb1dae2c225a9d6301150c6310f6959e11bdded5136bb3021f2b92"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('fsod': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
