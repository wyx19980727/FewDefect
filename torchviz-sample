digraph {
	graph [size="153.15,153.15"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140477509395632 [label="
 (1000, 4)" fillcolor=darkolivegreen1]
	140476809973008 [label=MulBackward0]
	140476809973648 -> 140476809973008
	140476809973648 [label=AddmmBackward]
	140476809971280 -> 140476809973648
	140478803778688 [label="roi_head.bbox_head.fc_cls.bias
 (4)" fillcolor=lightblue]
	140478803778688 -> 140476809971280
	140476809971280 [label=AccumulateGrad]
	140476809972368 -> 140476809973648
	140476809972368 [label=DivBackward0]
	140476809972688 -> 140476809972368
	140476809972688 [label=ReluBackward1]
	140478804184976 -> 140476809972688
	140478804184976 [label=AddmmBackward]
	140478804183888 -> 140478804184976
	140478803778528 [label="roi_head.bbox_head.shared_fcs.1.bias
 (1024)" fillcolor=lightblue]
	140478803778528 -> 140478804183888
	140478804183888 [label=AccumulateGrad]
	140478804181392 -> 140478804184976
	140478804181392 [label=ReluBackward1]
	140476809970320 -> 140478804181392
	140476809970320 [label=AddmmBackward]
	140477509058704 -> 140476809970320
	140478803777888 [label="roi_head.bbox_head.shared_fcs.0.bias
 (1024)" fillcolor=lightblue]
	140478803777888 -> 140477509058704
	140477509058704 [label=AccumulateGrad]
	140477509062032 -> 140476809970320
	140477509062032 [label=ViewBackward]
	140477509060688 -> 140477509062032
	140477509060688 [label=AddBackward0]
	140477509062416 -> 140477509060688
	140477509062416 [label=AddBackward0]
	140477509060752 -> 140477509062416
	140477509060752 [label=AddBackward0]
	140477509099024 -> 140477509060752
	140477509099024 [label=IndexPutBackward]
	140477509450640 -> 140477509099024
	140477509450640 [label=RoIAlignFunctionBackward]
	140477509099344 -> 140477509450640
	140477509099344 [label=AddBackward0]
	140477509098960 -> 140477509099344
	140477509098960 [label=CudnnConvolutionBackward]
	140477509098768 -> 140477509098960
	140477509098768 [label=AddBackward0]
	140477509099472 -> 140477509098768
	140477509099472 [label=AddBackward0]
	140477509096080 -> 140477509099472
	140477509096080 [label=CudnnConvolutionBackward]
	140477509097872 -> 140477509096080
	140478803967664 [label="neck.lateral_convs.0.conv.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	140478803967664 -> 140477509097872
	140477509097872 [label=AccumulateGrad]
	140477509098832 -> 140477509099472
	140477509098832 [label=ViewBackward]
	140477509061776 -> 140477509098832
	140478803967744 [label="neck.lateral_convs.0.conv.bias
 (256)" fillcolor=lightblue]
	140478803967744 -> 140477509061776
	140477509061776 [label=AccumulateGrad]
	140477509098448 -> 140477509098768
	140477509098448 [label=UpsampleNearest2DBackward1]
	140477509097424 -> 140477509098448
	140477509097424 [label=AddBackward0]
	140477509096848 -> 140477509097424
	140477509096848 [label=AddBackward0]
	140478971299792 -> 140477509096848
	140478971299792 [label=CudnnConvolutionBackward]
	140478845656080 -> 140478971299792
	140478845656080 [label=ReluBackward1]
	140478845655056 -> 140478845656080
	140478845655056 [label=AddBackward0]
	140478845656720 -> 140478845655056
	140478845656720 [label=CudnnBatchNormBackward]
	140478845656912 -> 140478845656720
	140478845656912 [label=CudnnConvolutionBackward]
	140478845654160 -> 140478845656912
	140478845654160 [label=ReluBackward1]
	140478845654032 -> 140478845654160
	140478845654032 [label=CudnnBatchNormBackward]
	140478845656848 -> 140478845654032
	140478845656848 [label=CudnnConvolutionBackward]
	140478845655376 -> 140478845656848
	140478845655376 [label=ReluBackward1]
	140478845653904 -> 140478845655376
	140478845653904 [label=CudnnBatchNormBackward]
	140478845656592 -> 140478845653904
	140478845656592 [label=CudnnConvolutionBackward]
	140478845656016 -> 140478845656592
	140478845656016 [label=ReluBackward1]
	140478845654608 -> 140478845656016
	140478845654608 [label=AddBackward0]
	140478845656656 -> 140478845654608
	140478845656656 [label=CudnnBatchNormBackward]
	140478845655568 -> 140478845656656
	140478845655568 [label=CudnnConvolutionBackward]
	140478845655440 -> 140478845655568
	140478845655440 [label=ReluBackward1]
	140478845655696 -> 140478845655440
	140478845655696 [label=CudnnBatchNormBackward]
	140478845654480 -> 140478845655696
	140478845654480 [label=CudnnConvolutionBackward]
	140478845653648 -> 140478845654480
	140478845653648 [label=ReluBackward1]
	140478845599888 -> 140478845653648
	140478845599888 [label=CudnnBatchNormBackward]
	140478845603600 -> 140478845599888
	140478845603600 [label=CudnnConvolutionBackward]
	140478845655760 -> 140478845603600
	140478845655760 [label=ReluBackward1]
	140478845603408 -> 140478845655760
	140478845603408 [label=AddBackward0]
	140478845600720 -> 140478845603408
	140478845600720 [label=CudnnBatchNormBackward]
	140478845603152 -> 140478845600720
	140478845603152 [label=CudnnConvolutionBackward]
	140478845600592 -> 140478845603152
	140478845600592 [label=ReluBackward1]
	140478845600144 -> 140478845600592
	140478845600144 [label=CudnnBatchNormBackward]
	140478845600336 -> 140478845600144
	140478845600336 [label=CudnnConvolutionBackward]
	140478845601424 -> 140478845600336
	140478845601424 [label=ReluBackward1]
	140478845601360 -> 140478845601424
	140478845601360 [label=CudnnBatchNormBackward]
	140478845603344 -> 140478845601360
	140478845603344 [label=CudnnConvolutionBackward]
	140478845602640 -> 140478845603344
	140478845602640 [label=ReluBackward1]
	140478845601744 -> 140478845602640
	140478845601744 [label=AddBackward0]
	140478845603536 -> 140478845601744
	140478845603536 [label=CudnnBatchNormBackward]
	140478845602256 -> 140478845603536
	140478845602256 [label=CudnnConvolutionBackward]
	140478845602192 -> 140478845602256
	140478845602192 [label=ReluBackward1]
	140478846377680 -> 140478845602192
	140478846377680 [label=CudnnBatchNormBackward]
	140478846377232 -> 140478846377680
	140478846377232 [label=CudnnConvolutionBackward]
	140478845584976 -> 140478846377232
	140478845584976 [label=ReluBackward1]
	140478845583440 -> 140478845584976
	140478845583440 [label=CudnnBatchNormBackward]
	140478845583696 -> 140478845583440
	140478845583696 [label=CudnnConvolutionBackward]
	140478845584720 -> 140478845583696
	140476809957200 [label="backbone.layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	140476809957200 -> 140478845584720
	140478845584720 [label=AccumulateGrad]
	140478845583952 -> 140478845583440
	140478803962928 [label="backbone.layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	140478803962928 -> 140478845583952
	140478845583952 [label=AccumulateGrad]
	140478845584400 -> 140478845583440
	140478803961808 [label="backbone.layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	140478803961808 -> 140478845584400
	140478845584400 [label=AccumulateGrad]
	140478845584080 -> 140478846377232
	140476809956640 [label="backbone.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140476809956640 -> 140478845584080
	140478845584080 [label=AccumulateGrad]
	140478846377552 -> 140478846377680
	140478803963648 [label="backbone.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	140478803963648 -> 140478846377552
	140478846377552 [label=AccumulateGrad]
	140478846377296 -> 140478846377680
	140478803963408 [label="backbone.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	140478803963408 -> 140478846377296
	140478846377296 [label=AccumulateGrad]
	140478845601872 -> 140478845602256
	140476809956400 [label="backbone.layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140476809956400 -> 140478845601872
	140478845601872 [label=AccumulateGrad]
	140478845603024 -> 140478845603536
	140476809953600 [label="backbone.layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	140476809953600 -> 140478845603024
	140478845603024 [label=AccumulateGrad]
	140478845603216 -> 140478845603536
	140476809955040 [label="backbone.layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	140476809955040 -> 140478845603216
	140478845603216 [label=AccumulateGrad]
	140478845602128 -> 140478845601744
	140478845602128 [label=CudnnBatchNormBackward]
	140478845602832 -> 140478845602128
	140478845602832 [label=CudnnConvolutionBackward]
	140478845584656 -> 140478845602832
	140478803963248 [label="backbone.layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140478803963248 -> 140478845584656
	140478845584656 [label=AccumulateGrad]
	140478846377744 -> 140478845602128
	140478803962528 [label="backbone.layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	140478803962528 -> 140478846377744
	140478846377744 [label=AccumulateGrad]
	140478846377168 -> 140478845602128
	140478803963328 [label="backbone.layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	140478803963328 -> 140478846377168
	140478846377168 [label=AccumulateGrad]
	140478845602320 -> 140478845603344
	140476809955360 [label="backbone.layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	140476809955360 -> 140478845602320
	140478845602320 [label=AccumulateGrad]
	140478845602384 -> 140478845601360
	140476809957120 [label="backbone.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	140476809957120 -> 140478845602384
	140478845602384 [label=AccumulateGrad]
	140478845602768 -> 140478845601360
	140476809956080 [label="backbone.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	140476809956080 -> 140478845602768
	140478845602768 [label=AccumulateGrad]
	140478845600208 -> 140478845600336
	140476809955200 [label="backbone.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140476809955200 -> 140478845600208
	140478845600208 [label=AccumulateGrad]
	140478845601552 -> 140478845600144
	140476809953360 [label="backbone.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	140476809953360 -> 140478845601552
	140478845601552 [label=AccumulateGrad]
	140478845600848 -> 140478845600144
	140476809955920 [label="backbone.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	140476809955920 -> 140478845600848
	140478845600848 [label=AccumulateGrad]
	140478845601232 -> 140478845603152
	140478803550688 [label="backbone.layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140478803550688 -> 140478845601232
	140478845601232 [label=AccumulateGrad]
	140478845601040 -> 140478845600720
	140476809954720 [label="backbone.layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	140476809954720 -> 140478845601040
	140478845601040 [label=AccumulateGrad]
	140478845600656 -> 140478845600720
	140476809953680 [label="backbone.layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	140476809953680 -> 140478845600656
	140478845600656 [label=AccumulateGrad]
	140478845602640 -> 140478845603408
	140478845602960 -> 140478845603600
	140478804352768 [label="backbone.layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	140478804352768 -> 140478845602960
	140478845602960 [label=AccumulateGrad]
	140478845603472 -> 140478845599888
	140478803550928 [label="backbone.layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	140478803550928 -> 140478845603472
	140478845603472 [label=AccumulateGrad]
	140478845602512 -> 140478845599888
	140478803551168 [label="backbone.layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	140478803551168 -> 140478845602512
	140478845602512 [label=AccumulateGrad]
	140478845653392 -> 140478845654480
	140478804352368 [label="backbone.layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140478804352368 -> 140478845653392
	140478845653392 [label=AccumulateGrad]
	140478845656528 -> 140478845655696
	140478803551248 [label="backbone.layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	140478803551248 -> 140478845656528
	140478845656528 [label=AccumulateGrad]
	140478845653968 -> 140478845655696
	140478803551088 [label="backbone.layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	140478803551088 -> 140478845653968
	140478845653968 [label=AccumulateGrad]
	140478845654800 -> 140478845655568
	140478804352288 [label="backbone.layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140478804352288 -> 140478845654800
	140478845654800 [label=AccumulateGrad]
	140478845654864 -> 140478845656656
	140478803550288 [label="backbone.layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	140478803550288 -> 140478845654864
	140478845654864 [label=AccumulateGrad]
	140478845655248 -> 140478845656656
	140478804351408 [label="backbone.layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	140478804351408 -> 140478845655248
	140478845655248 [label=AccumulateGrad]
	140478845655760 -> 140478845654608
	140478845653520 -> 140478845656592
	140478804321856 [label="backbone.layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	140478804321856 -> 140478845653520
	140478845653520 [label=AccumulateGrad]
	140478845654992 -> 140478845653904
	140478804351808 [label="backbone.layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	140478804351808 -> 140478845654992
	140478845654992 [label=AccumulateGrad]
	140478845655888 -> 140478845653904
	140478804322096 [label="backbone.layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	140478804322096 -> 140478845655888
	140478845655888 [label=AccumulateGrad]
	140478845654928 -> 140478845656848
	140478804322656 [label="backbone.layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140478804322656 -> 140478845654928
	140478845654928 [label=AccumulateGrad]
	140478845655824 -> 140478845654032
	140478804324176 [label="backbone.layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	140478804324176 -> 140478845655824
	140478845655824 [label=AccumulateGrad]
	140478845656272 -> 140478845654032
	140478804322016 [label="backbone.layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	140478804322016 -> 140478845656272
	140478845656272 [label=AccumulateGrad]
	140478845653584 -> 140478845656912
	140478804321296 [label="backbone.layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140478804321296 -> 140478845653584
	140478845653584 [label=AccumulateGrad]
	140478845656208 -> 140478845656720
	140478804322416 [label="backbone.layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	140478804322416 -> 140478845656208
	140478845656208 [label=AccumulateGrad]
	140478845654672 -> 140478845656720
	140478804323136 [label="backbone.layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	140478804323136 -> 140478845654672
	140478845654672 [label=AccumulateGrad]
	140478845656016 -> 140478845655056
	140478845653136 -> 140478971299792
	140478803870176 [label="neck.lateral_convs.1.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	140478803870176 -> 140478845653136
	140478845653136 [label=AccumulateGrad]
	140477509099280 -> 140477509096848
	140477509099280 [label=ViewBackward]
	140477509096784 -> 140477509099280
	140478803870256 [label="neck.lateral_convs.1.conv.bias
 (256)" fillcolor=lightblue]
	140478803870256 -> 140477509096784
	140477509096784 [label=AccumulateGrad]
	140477509097744 -> 140477509097424
	140477509097744 [label=UpsampleNearest2DBackward1]
	140477509098704 -> 140477509097744
	140477509098704 [label=AddBackward0]
	140478845653200 -> 140477509098704
	140478845653200 [label=AddBackward0]
	140478845655504 -> 140478845653200
	140478845655504 [label=CudnnConvolutionBackward]
	140478845657040 -> 140478845655504
	140478845657040 [label=ReluBackward1]
	140478845656784 -> 140478845657040
	140478845656784 [label=AddBackward0]
	140478845656464 -> 140478845656784
	140478845656464 [label=CudnnBatchNormBackward]
	140478845655312 -> 140478845656464
	140478845655312 [label=CudnnConvolutionBackward]
	140478845600784 -> 140478845655312
	140478845600784 [label=ReluBackward1]
	140478845601680 -> 140478845600784
	140478845601680 [label=CudnnBatchNormBackward]
	140478845603728 -> 140478845601680
	140478845603728 [label=CudnnConvolutionBackward]
	140478845601808 -> 140478845603728
	140478845601808 [label=ReluBackward1]
	140478845602704 -> 140478845601808
	140478845602704 [label=CudnnBatchNormBackward]
	140478845583568 -> 140478845602704
	140478845583568 [label=CudnnConvolutionBackward]
	140478845654224 -> 140478845583568
	140478845654224 [label=ReluBackward1]
	140478845584272 -> 140478845654224
	140478845584272 [label=AddBackward0]
	140478845584592 -> 140478845584272
	140478845584592 [label=CudnnBatchNormBackward]
	140478845584016 -> 140478845584592
	140478845584016 [label=CudnnConvolutionBackward]
	140478845585872 -> 140478845584016
	140478845585872 [label=ReluBackward1]
	140478845586512 -> 140478845585872
	140478845586512 [label=CudnnBatchNormBackward]
	140478845585040 -> 140478845586512
	140478845585040 [label=CudnnConvolutionBackward]
	140478845585808 -> 140478845585040
	140478845585808 [label=ReluBackward1]
	140478845585680 -> 140478845585808
	140478845585680 [label=CudnnBatchNormBackward]
	140478845585936 -> 140478845585680
	140478845585936 [label=CudnnConvolutionBackward]
	140478845583888 -> 140478845585936
	140478845583888 [label=ReluBackward1]
	140478845587216 -> 140478845583888
	140478845587216 [label=AddBackward0]
	140478845586640 -> 140478845587216
	140478845586640 [label=CudnnBatchNormBackward]
	140478845587024 -> 140478845586640
	140478845587024 [label=CudnnConvolutionBackward]
	140478804122064 -> 140478845587024
	140478804122064 [label=ReluBackward1]
	140478804122448 -> 140478804122064
	140478804122448 [label=CudnnBatchNormBackward]
	140478804121808 -> 140478804122448
	140478804121808 [label=CudnnConvolutionBackward]
	140478804122192 -> 140478804121808
	140478804122192 [label=ReluBackward1]
	140478804119696 -> 140478804122192
	140478804119696 [label=CudnnBatchNormBackward]
	140478804119760 -> 140478804119696
	140478804119760 [label=CudnnConvolutionBackward]
	140478845586960 -> 140478804119760
	140478845586960 [label=ReluBackward1]
	140478804119888 -> 140478845586960
	140478804119888 [label=AddBackward0]
	140478804123408 -> 140478804119888
	140478804123408 [label=CudnnBatchNormBackward]
	140478804120976 -> 140478804123408
	140478804120976 [label=CudnnConvolutionBackward]
	140478804119824 -> 140478804120976
	140478804119824 [label=ReluBackward1]
	140478804119632 -> 140478804119824
	140478804119632 [label=CudnnBatchNormBackward]
	140478804122832 -> 140478804119632
	140478804122832 [label=CudnnConvolutionBackward]
	140478804122384 -> 140478804122832
	140478804122384 [label=ReluBackward1]
	140478804120400 -> 140478804122384
	140478804120400 [label=CudnnBatchNormBackward]
	140478804121296 -> 140478804120400
	140478804121296 [label=CudnnConvolutionBackward]
	140478804123472 -> 140478804121296
	140478804123472 [label=ReluBackward1]
	140478804121552 -> 140478804123472
	140478804121552 [label=AddBackward0]
	140478804120720 -> 140478804121552
	140478804120720 [label=CudnnBatchNormBackward]
	140477508997712 -> 140478804120720
	140477508997712 [label=CudnnConvolutionBackward]
	140477509764432 -> 140477508997712
	140477509764432 [label=ReluBackward1]
	140477509763344 -> 140477509764432
	140477509763344 [label=CudnnBatchNormBackward]
	140477509764048 -> 140477509763344
	140477509764048 [label=CudnnConvolutionBackward]
	140477509765456 -> 140477509764048
	140477509765456 [label=ReluBackward1]
	140477509764624 -> 140477509765456
	140477509764624 [label=CudnnBatchNormBackward]
	140477509764560 -> 140477509764624
	140477509764560 [label=CudnnConvolutionBackward]
	140478804121168 -> 140477509764560
	140478804121168 [label=ReluBackward1]
	140478804376080 -> 140478804121168
	140478804376080 [label=AddBackward0]
	140478804375312 -> 140478804376080
	140478804375312 [label=CudnnBatchNormBackward]
	140478804375120 -> 140478804375312
	140478804375120 [label=CudnnConvolutionBackward]
	140478804376016 -> 140478804375120
	140478804376016 [label=ReluBackward1]
	140478635850384 -> 140478804376016
	140478635850384 [label=CudnnBatchNormBackward]
	140478635849936 -> 140478635850384
	140478635849936 [label=CudnnConvolutionBackward]
	140478635850576 -> 140478635849936
	140478635850576 [label=ReluBackward1]
	140478635850192 -> 140478635850576
	140478635850192 [label=CudnnBatchNormBackward]
	140478635850896 -> 140478635850192
	140478635850896 [label=CudnnConvolutionBackward]
	140478845656080 -> 140478635850896
	140477509916368 -> 140478635850896
	140478803993936 [label="backbone.layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	140478803993936 -> 140477509916368
	140477509916368 [label=AccumulateGrad]
	140478635850832 -> 140478635850192
	140478804320576 [label="backbone.layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	140478804320576 -> 140478635850832
	140478635850832 [label=AccumulateGrad]
	140478635851280 -> 140478635850192
	140478804321056 [label="backbone.layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	140478804321056 -> 140478635851280
	140478635851280 [label=AccumulateGrad]
	140478635851536 -> 140478635849936
	140478803995936 [label="backbone.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140478803995936 -> 140478635851536
	140478635851536 [label=AccumulateGrad]
	140478635851024 -> 140478635850384
	140478804321696 [label="backbone.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	140478804321696 -> 140478635851024
	140478635851024 [label=AccumulateGrad]
	140478635850640 -> 140478635850384
	140478804321776 [label="backbone.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	140478804321776 -> 140478635850640
	140478635850640 [label=AccumulateGrad]
	140478635851152 -> 140478804375120
	140478803996576 [label="backbone.layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140478803996576 -> 140478635851152
	140478635851152 [label=AccumulateGrad]
	140478804375248 -> 140478804375312
	140477509367520 [label="backbone.layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	140477509367520 -> 140478804375248
	140478804375248 [label=AccumulateGrad]
	140478804376592 -> 140478804375312
	140477509369600 [label="backbone.layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	140477509369600 -> 140478804376592
	140478804376592 [label=AccumulateGrad]
	140478804375184 -> 140478804376080
	140478804375184 [label=CudnnBatchNormBackward]
	140478804377488 -> 140478804375184
	140478804377488 [label=CudnnConvolutionBackward]
	140478845656080 -> 140478804377488
	140478635850320 -> 140478804377488
	140478804321216 [label="backbone.layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	140478804321216 -> 140478635850320
	140478635850320 [label=AccumulateGrad]
	140478635851088 -> 140478804375184
	140478804322176 [label="backbone.layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	140478804322176 -> 140478635851088
	140478635851088 [label=AccumulateGrad]
	140478635851408 -> 140478804375184
	140478804321536 [label="backbone.layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	140478804321536 -> 140478635851408
	140478635851408 [label=AccumulateGrad]
	140478804375888 -> 140477509764560
	140478804408912 [label="backbone.layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140478804408912 -> 140478804375888
	140478804375888 [label=AccumulateGrad]
	140478803947344 -> 140477509764624
	140478803993216 [label="backbone.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	140478803993216 -> 140478803947344
	140478803947344 [label=AccumulateGrad]
	140478803947088 -> 140477509764624
	140478803995136 [label="backbone.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	140478803995136 -> 140478803947088
	140478803947088 [label=AccumulateGrad]
	140477509764880 -> 140477509764048
	140478804409552 [label="backbone.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140478804409552 -> 140477509764880
	140477509764880 [label=AccumulateGrad]
	140477509765328 -> 140477509763344
	140477509887872 [label="backbone.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	140477509887872 -> 140477509765328
	140477509765328 [label=AccumulateGrad]
	140477509764688 -> 140477509763344
	140477509888272 [label="backbone.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	140477509888272 -> 140477509764688
	140477509764688 [label=AccumulateGrad]
	140477509764112 -> 140477508997712
	140478804408832 [label="backbone.layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140478804408832 -> 140477509764112
	140477509764112 [label=AccumulateGrad]
	140477508997648 -> 140478804120720
	140478804409872 [label="backbone.layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	140478804409872 -> 140477508997648
	140477508997648 [label=AccumulateGrad]
	140478804121424 -> 140478804120720
	140478804407552 [label="backbone.layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	140478804407552 -> 140478804121424
	140478804121424 [label=AccumulateGrad]
	140478804121168 -> 140478804121552
	140478804121040 -> 140478804121296
	140478804157296 [label="backbone.layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140478804157296 -> 140478804121040
	140478804121040 [label=AccumulateGrad]
	140478804120912 -> 140478804120400
	140478804406432 [label="backbone.layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	140478804406432 -> 140478804120912
	140478804120912 [label=AccumulateGrad]
	140478804120464 -> 140478804120400
	140478804407792 [label="backbone.layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	140478804407792 -> 140478804120464
	140478804120464 [label=AccumulateGrad]
	140478804123536 -> 140478804122832
	140478804159616 [label="backbone.layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140478804159616 -> 140478804123536
	140478804123536 [label=AccumulateGrad]
	140478804122768 -> 140478804119632
	140478804408272 [label="backbone.layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	140478804408272 -> 140478804122768
	140478804122768 [label=AccumulateGrad]
	140478804122896 -> 140478804119632
	140478804408432 [label="backbone.layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	140478804408432 -> 140478804122896
	140478804122896 [label=AccumulateGrad]
	140478804123344 -> 140478804120976
	140478804158976 [label="backbone.layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140478804158976 -> 140478804123344
	140478804123344 [label=AccumulateGrad]
	140478804122512 -> 140478804123408
	140478804159056 [label="backbone.layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	140478804159056 -> 140478804122512
	140478804122512 [label=AccumulateGrad]
	140478804122960 -> 140478804123408
	140478804157696 [label="backbone.layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	140478804157696 -> 140478804122960
	140478804122960 [label=AccumulateGrad]
	140478804123472 -> 140478804119888
	140478804119952 -> 140478804119760
	140478804156576 [label="backbone.layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140478804156576 -> 140478804119952
	140478804119952 [label=AccumulateGrad]
	140478804120656 -> 140478804119696
	140478804159696 [label="backbone.layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	140478804159696 -> 140478804120656
	140478804120656 [label=AccumulateGrad]
	140478804123024 -> 140478804119696
	140478804159536 [label="backbone.layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	140478804159536 -> 140478804123024
	140478804123024 [label=AccumulateGrad]
	140478804120848 -> 140478804121808
	140478804151824 [label="backbone.layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140478804151824 -> 140478804120848
	140478804120848 [label=AccumulateGrad]
	140478804122256 -> 140478804122448
	140478804159376 [label="backbone.layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	140478804159376 -> 140478804122256
	140478804122256 [label=AccumulateGrad]
	140478804122000 -> 140478804122448
	140478804156736 [label="backbone.layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	140478804156736 -> 140478804122000
	140478804122000 [label=AccumulateGrad]
	140478804123600 -> 140478845587024
	140478804151024 [label="backbone.layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140478804151024 -> 140478804123600
	140478804123600 [label=AccumulateGrad]
	140478804121744 -> 140478845586640
	140478804158496 [label="backbone.layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	140478804158496 -> 140478804121744
	140478804121744 [label=AccumulateGrad]
	140478804121936 -> 140478845586640
	140478804158576 [label="backbone.layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	140478804158576 -> 140478804121936
	140478804121936 [label=AccumulateGrad]
	140478845586960 -> 140478845587216
	140478845586832 -> 140478845585936
	140478804149264 [label="backbone.layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140478804149264 -> 140478845586832
	140478845586832 [label=AccumulateGrad]
	140478845585616 -> 140478845585680
	140478804151504 [label="backbone.layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	140478804151504 -> 140478845585616
	140478845585616 [label=AccumulateGrad]
	140478845586128 -> 140478845585680
	140478804150144 [label="backbone.layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	140478804150144 -> 140478845586128
	140478845586128 [label=AccumulateGrad]
	140478845586000 -> 140478845585040
	140478804149744 [label="backbone.layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140478804149744 -> 140478845586000
	140478845586000 [label=AccumulateGrad]
	140478845587408 -> 140478845586512
	140478804150864 [label="backbone.layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	140478804150864 -> 140478845587408
	140478845587408 [label=AccumulateGrad]
	140478845585424 -> 140478845586512
	140478804151984 [label="backbone.layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	140478804151984 -> 140478845585424
	140478845585424 [label=AccumulateGrad]
	140478845585488 -> 140478845584016
	140478804149824 [label="backbone.layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140478804149824 -> 140478845585488
	140478845585488 [label=AccumulateGrad]
	140478845585552 -> 140478845584592
	140478804150704 [label="backbone.layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	140478804150704 -> 140478845585552
	140478845585552 [label=AccumulateGrad]
	140478845583760 -> 140478845584592
	140478804152144 [label="backbone.layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	140478804152144 -> 140478845583760
	140478845583760 [label=AccumulateGrad]
	140478845583888 -> 140478845584272
	140478845584208 -> 140478845583568
	140476810024672 [label="backbone.layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140476810024672 -> 140478845584208
	140478845584208 [label=AccumulateGrad]
	140478845583632 -> 140478845602704
	140478804148704 [label="backbone.layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	140478804148704 -> 140478845583632
	140478845583632 [label=AccumulateGrad]
	140478845586704 -> 140478845602704
	140478804150304 [label="backbone.layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	140478804150304 -> 140478845586704
	140478845586704 [label=AccumulateGrad]
	140478845602064 -> 140478845603728
	140476810023712 [label="backbone.layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140476810023712 -> 140478845602064
	140478845602064 [label=AccumulateGrad]
	140478845599824 -> 140478845601680
	140478804149024 [label="backbone.layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	140478804149024 -> 140478845599824
	140478845599824 [label=AccumulateGrad]
	140478845600912 -> 140478845601680
	140478804151584 [label="backbone.layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	140478804151584 -> 140478845600912
	140478845600912 [label=AccumulateGrad]
	140478845603792 -> 140478845655312
	140476810024272 [label="backbone.layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140476810024272 -> 140478845603792
	140478845603792 [label=AccumulateGrad]
	140478845654096 -> 140478845656464
	140476810024512 [label="backbone.layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	140476810024512 -> 140478845654096
	140478845654096 [label=AccumulateGrad]
	140478845601616 -> 140478845656464
	140476810023472 [label="backbone.layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	140476810023472 -> 140478845601616
	140478845601616 [label=AccumulateGrad]
	140478845654224 -> 140478845656784
	140478845656400 -> 140478845655504
	140478803870816 [label="neck.lateral_convs.2.conv.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140478803870816 -> 140478845656400
	140478845656400 [label=AccumulateGrad]
	140478845655184 -> 140478845653200
	140478845655184 [label=ViewBackward]
	140478845653328 -> 140478845655184
	140478803870896 [label="neck.lateral_convs.2.conv.bias
 (256)" fillcolor=lightblue]
	140478803870896 -> 140478845653328
	140478845653328 [label=AccumulateGrad]
	140478845655120 -> 140477509098704
	140478845655120 [label=UpsampleNearest2DBackward1]
	140478845654352 -> 140478845655120
	140478845654352 [label=AddBackward0]
	140478845656976 -> 140478845654352
	140478845656976 [label=CudnnConvolutionBackward]
	140478635850064 -> 140478845656976
	140478635850064 [label=ReluBackward1]
	140478845602896 -> 140478635850064
	140478845602896 [label=AddBackward0]
	140478845584144 -> 140478845602896
	140478845584144 [label=CudnnBatchNormBackward]
	140478845584528 -> 140478845584144
	140478845584528 [label=CudnnConvolutionBackward]
	140478845584848 -> 140478845584528
	140478845584848 [label=ReluBackward1]
	140478803946512 -> 140478845584848
	140478803946512 [label=CudnnBatchNormBackward]
	140478845587088 -> 140478803946512
	140478845587088 [label=CudnnConvolutionBackward]
	140478804123280 -> 140478845587088
	140478804123280 [label=ReluBackward1]
	140478804121680 -> 140478804123280
	140478804121680 [label=CudnnBatchNormBackward]
	140478804121232 -> 140478804121680
	140478804121232 [label=CudnnConvolutionBackward]
	140478845586192 -> 140478804121232
	140478845586192 [label=ReluBackward1]
	140478804121360 -> 140478845586192
	140478804121360 [label=AddBackward0]
	140478804121104 -> 140478804121360
	140478804121104 [label=CudnnBatchNormBackward]
	140478804120272 -> 140478804121104
	140478804120272 [label=CudnnConvolutionBackward]
	140477509764176 -> 140478804120272
	140477509764176 [label=ReluBackward1]
	140478804374864 -> 140477509764176
	140478804374864 [label=CudnnBatchNormBackward]
	140478804374992 -> 140478804374864
	140478804374992 [label=CudnnConvolutionBackward]
	140477509916240 -> 140478804374992
	140477509916240 [label=ReluBackward1]
	140477509916560 -> 140477509916240
	140477509916560 [label=CudnnBatchNormBackward]
	140477509916112 -> 140477509916560
	140477509916112 [label=CudnnConvolutionBackward]
	140478804120336 -> 140477509916112
	140478804120336 [label=ReluBackward1]
	140477509916688 -> 140478804120336
	140477509916688 [label=AddBackward0]
	140477509916624 -> 140477509916688
	140477509916624 [label=CudnnBatchNormBackward]
	140478845630544 -> 140477509916624
	140478845630544 [label=CudnnConvolutionBackward]
	140478845630480 -> 140478845630544
	140478845630480 [label=ReluBackward1]
	140478845630864 -> 140478845630480
	140478845630864 [label=CudnnBatchNormBackward]
	140478845629328 -> 140478845630864
	140478845629328 [label=CudnnConvolutionBackward]
	140478845630608 -> 140478845629328
	140478845630608 [label=ReluBackward1]
	140478845629840 -> 140478845630608
	140478845629840 [label=CudnnBatchNormBackward]
	140478845631120 -> 140478845629840
	140478845631120 [label=CudnnConvolutionBackward]
	140478845657040 -> 140478845631120
	140478845631376 -> 140478845631120
	140478804127008 [label="backbone.layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	140478804127008 -> 140478845631376
	140478845631376 [label=AccumulateGrad]
	140478845631568 -> 140478845629840
	140478804125168 [label="backbone.layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	140478804125168 -> 140478845631568
	140478845631568 [label=AccumulateGrad]
	140478845630096 -> 140478845629840
	140478804126448 [label="backbone.layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	140478804126448 -> 140478845630096
	140478845630096 [label=AccumulateGrad]
	140478845630992 -> 140478845629328
	140478804125328 [label="backbone.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140478804125328 -> 140478845630992
	140478845630992 [label=AccumulateGrad]
	140478845629264 -> 140478845630864
	140478804126928 [label="backbone.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	140478804126928 -> 140478845629264
	140478845629264 [label=AccumulateGrad]
	140478845631312 -> 140478845630864
	140478804124928 [label="backbone.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	140478804124928 -> 140478845631312
	140478845631312 [label=AccumulateGrad]
	140478845629904 -> 140478845630544
	140478804126528 [label="backbone.layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	140478804126528 -> 140478845629904
	140478845629904 [label=AccumulateGrad]
	140478845632208 -> 140477509916624
	140478804126208 [label="backbone.layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	140478804126208 -> 140478845632208
	140478845632208 [label=AccumulateGrad]
	140478845631888 -> 140477509916624
	140478804127088 [label="backbone.layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	140478804127088 -> 140478845631888
	140478845631888 [label=AccumulateGrad]
	140477509915792 -> 140477509916688
	140477509915792 [label=CudnnBatchNormBackward]
	140478845601488 -> 140477509915792
	140478845601488 [label=CudnnConvolutionBackward]
	140478845657040 -> 140478845601488
	140478845628688 -> 140478845601488
	140476810023632 [label="backbone.layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	140476810023632 -> 140478845628688
	140478845628688 [label=AccumulateGrad]
	140478845632272 -> 140477509915792
	140476810023952 [label="backbone.layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	140476810023952 -> 140478845632272
	140478845632272 [label=AccumulateGrad]
	140478845631248 -> 140477509915792
	140476810023552 [label="backbone.layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	140476810023552 -> 140478845631248
	140478845631248 [label=AccumulateGrad]
	140477509915984 -> 140477509916112
	140478803964864 [label="backbone.layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	140478803964864 -> 140477509915984
	140477509915984 [label=AccumulateGrad]
	140477509916752 -> 140477509916560
	140478804127248 [label="backbone.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	140478804127248 -> 140477509916752
	140477509916752 [label=AccumulateGrad]
	140477509916816 -> 140477509916560
	140477509503808 [label="backbone.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	140477509503808 -> 140477509916816
	140477509916816 [label=AccumulateGrad]
	140477509915664 -> 140478804374992
	140478803965104 [label="backbone.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140478803965104 -> 140477509915664
	140477509915664 [label=AccumulateGrad]
	140477509764752 -> 140478804374864
	140477509603152 [label="backbone.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	140477509603152 -> 140477509764752
	140477509764752 [label=AccumulateGrad]
	140477509764496 -> 140478804374864
	140477509603072 [label="backbone.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	140477509603072 -> 140477509764496
	140477509764496 [label=AccumulateGrad]
	140477509763600 -> 140478804120272
	140478803965264 [label="backbone.layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	140478803965264 -> 140477509763600
	140477509763600 [label=AccumulateGrad]
	140478804120784 -> 140478804121104
	140478803964304 [label="backbone.layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	140478803964304 -> 140478804120784
	140478804120784 [label=AccumulateGrad]
	140478804121488 -> 140478804121104
	140478803964224 [label="backbone.layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	140478803964224 -> 140478804121488
	140478804121488 [label=AccumulateGrad]
	140478804120336 -> 140478804121360
	140478804122128 -> 140478804121232
	140478803967104 [label="backbone.layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	140478803967104 -> 140478804122128
	140478804122128 [label=AccumulateGrad]
	140478804122640 -> 140478804121680
	140478803965184 [label="backbone.layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	140478803965184 -> 140478804122640
	140478804122640 [label=AccumulateGrad]
	140478804120208 -> 140478804121680
	140478803965504 [label="backbone.layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	140478803965504 -> 140478804120208
	140478804120208 [label=AccumulateGrad]
	140478804122320 -> 140478845587088
	140478803967344 [label="backbone.layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140478803967344 -> 140478804122320
	140478804122320 [label=AccumulateGrad]
	140478845586576 -> 140478803946512
	140478803966064 [label="backbone.layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	140478803966064 -> 140478845586576
	140478845586576 [label=AccumulateGrad]
	140478845585168 -> 140478803946512
	140478803965984 [label="backbone.layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	140478803965984 -> 140478845585168
	140478845585168 [label=AccumulateGrad]
	140478845585104 -> 140478845584528
	140478803967504 [label="backbone.layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	140478803967504 -> 140478845585104
	140478845585104 [label=AccumulateGrad]
	140478845585232 -> 140478845584144
	140478803966544 [label="backbone.layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	140478803966544 -> 140478845585232
	140478845585232 [label=AccumulateGrad]
	140478845584464 -> 140478845584144
	140478803966464 [label="backbone.layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	140478803966464 -> 140478845584464
	140478845584464 [label=AccumulateGrad]
	140478845586192 -> 140478845602896
	140478635850128 -> 140478845656976
	140478803871456 [label="neck.lateral_convs.3.conv.weight
 (256, 2048, 1, 1)" fillcolor=lightblue]
	140478803871456 -> 140478635850128
	140478635850128 [label=AccumulateGrad]
	140478845600080 -> 140478845654352
	140478845600080 [label=ViewBackward]
	140478845600400 -> 140478845600080
	140478803871536 [label="neck.lateral_convs.3.conv.bias
 (256)" fillcolor=lightblue]
	140478803871536 -> 140478845600400
	140478845600400 [label=AccumulateGrad]
	140477509096336 -> 140477509098960
	140478803869856 [label="neck.fpn_convs.0.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140478803869856 -> 140477509096336
	140477509096336 [label=AccumulateGrad]
	140477509097296 -> 140477509099344
	140477509097296 [label=ViewBackward]
	140478845653840 -> 140477509097296
	140478803869936 [label="neck.fpn_convs.0.conv.bias
 (256)" fillcolor=lightblue]
	140478803869936 -> 140478845653840
	140478845653840 [label=AccumulateGrad]
	140477509502768 -> 140477509450640
	140477509502768 [label="
 (513, 5)" fillcolor=orange]
	140477509501728 -> 140477509450640
	140477509501728 [label="
 (0)" fillcolor=orange]
	140477509504448 -> 140477509450640
	140477509504448 [label="
 (0)" fillcolor=orange]
	140477509097680 -> 140477509060752
	140477509097680 [label=AddBackward0]
	140478845601296 -> 140477509097680
	140478845601296 [label=MulBackward0]
	140478845655632 -> 140478845601296
	140478845655632 [label=SumBackward0]
	140477509098640 -> 140478845655632
	140477509098640 [label=AddBackward0]
	140478804376208 -> 140477509098640
	140478804376208 [label=CudnnConvolutionBackward]
	140477509097424 -> 140478804376208
	140477509098000 -> 140478804376208
	140478803870496 [label="neck.fpn_convs.1.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140478803870496 -> 140477509098000
	140477509098000 [label=AccumulateGrad]
	140477509097552 -> 140477509098640
	140477509097552 [label=ViewBackward]
	140477509099088 -> 140477509097552
	140478803870576 [label="neck.fpn_convs.1.conv.bias
 (256)" fillcolor=lightblue]
	140478803870576 -> 140477509099088
	140477509099088 [label=AccumulateGrad]
	140477509061584 -> 140477509062416
	140477509061584 [label=AddBackward0]
	140478845655952 -> 140477509061584
	140478845655952 [label=MulBackward0]
	140477509099216 -> 140478845655952
	140477509099216 [label=SumBackward0]
	140477509096976 -> 140477509099216
	140477509096976 [label=AddBackward0]
	140478845586448 -> 140477509096976
	140478845586448 [label=CudnnConvolutionBackward]
	140477509098704 -> 140478845586448
	140478804121616 -> 140478845586448
	140478803871136 [label="neck.fpn_convs.2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140478803871136 -> 140478804121616
	140478804121616 [label=AccumulateGrad]
	140478845587280 -> 140477509096976
	140478845587280 [label=ViewBackward]
	140478845583504 -> 140478845587280
	140478803871216 [label="neck.fpn_convs.2.conv.bias
 (256)" fillcolor=lightblue]
	140478803871216 -> 140478845583504
	140478845583504 [label=AccumulateGrad]
	140477509062608 -> 140477509060688
	140477509062608 [label=AddBackward0]
	140478845583824 -> 140477509062608
	140478845583824 [label=MulBackward0]
	140477509097040 -> 140478845583824
	140477509097040 [label=SumBackward0]
	140477509097360 -> 140477509097040
	140477509097360 [label=AddBackward0]
	140478804120080 -> 140477509097360
	140478804120080 [label=CudnnConvolutionBackward]
	140478845654352 -> 140478804120080
	140477509765264 -> 140478804120080
	140478803871776 [label="neck.fpn_convs.3.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140478803871776 -> 140477509765264
	140477509765264 [label=AccumulateGrad]
	140478804120528 -> 140477509097360
	140478804120528 [label=ViewBackward]
	140478804121872 -> 140478804120528
	140478803871856 [label="neck.fpn_convs.3.conv.bias
 (256)" fillcolor=lightblue]
	140478803871856 -> 140478804121872
	140478804121872 [label=AccumulateGrad]
	140477509062544 -> 140476809970320
	140477509062544 [label=TBackward]
	140477509098064 -> 140477509062544
	140478803777808 [label="roi_head.bbox_head.shared_fcs.0.weight
 (1024, 12544)" fillcolor=lightblue]
	140478803777808 -> 140477509098064
	140477509098064 [label=AccumulateGrad]
	140478804184528 -> 140478804184976
	140478804184528 [label=TBackward]
	140478845585744 -> 140478804184528
	140478803778448 [label="roi_head.bbox_head.shared_fcs.1.weight
 (1024, 1024)" fillcolor=lightblue]
	140478803778448 -> 140478845585744
	140478845585744 [label=AccumulateGrad]
	140476809972752 -> 140476809972368
	140476809972752 [label=AddBackward0]
	140477509061520 -> 140476809972752
	140477509061520 [label=ExpandBackward]
	140477509062352 -> 140477509061520
	140477509062352 [label=UnsqueezeBackward0]
	140478804184144 -> 140477509062352
	140478804184144 [label=NormBackward1]
	140476809972688 -> 140478804184144
	140476809970128 -> 140476809973648
	140476809970128 [label=TBackward]
	140477509061200 -> 140476809970128
	140478803778608 [label="roi_head.bbox_head.fc_cls.weight
 (4, 1024)" fillcolor=lightblue]
	140478803778608 -> 140477509061200
	140477509061200 [label=AccumulateGrad]
	140476809973008 -> 140477509395632
	140477509396992 [label="
 (1000, 12)" fillcolor=darkolivegreen1]
	140476809972432 [label=AddmmBackward]
	140476809972816 -> 140476809972432
	140478803778848 [label="roi_head.bbox_head.fc_reg.bias
 (12)" fillcolor=lightblue]
	140478803778848 -> 140476809972816
	140476809972816 [label=AccumulateGrad]
	140476809972688 -> 140476809972432
	140478804182224 -> 140476809972432
	140478804182224 [label=TBackward]
	140478804184912 -> 140478804182224
	140478803776928 [label="roi_head.bbox_head.fc_reg.weight
 (12, 1024)" fillcolor=lightblue]
	140478803776928 -> 140478804184912
	140478804184912 [label=AccumulateGrad]
	140476809972432 -> 140477509396992
}
